[[intro]]
== Introduction

Centralized application logging with the Elastic stack made easy.

[role="screenshot"]
image:https://user-images.githubusercontent.com/2163464/62682932-9cac3600-b9bd-11e9-9cc3-39e907280f8e.png[]

[float]
=== What is ECS?

Elastic Common Schema (ECS) defines a common set of fields for ingesting data into Elasticsearch.
For more information about ECS, visit the {ecs-ref}/ecs-reference.html[ECS Reference Documentation].

[float]
=== What is ECS logging?

ECS loggers are plugins for your favorite logging library.
They make it easy to format your logs into ECS-compatible JSON. For example:
[source,json]
----
{"@timestamp":"2019-08-06T12:09:12.375Z", "log.level": "INFO", "message":"Tomcat started on port(s): 8080 (http) with context path ''", "service.name":"spring-petclinic","process.thread.name":"restartedMain","log.logger":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer"}
{"@timestamp":"2019-08-06T12:09:12.379Z", "log.level": "INFO", "message":"Started PetClinicApplication in 7.095 seconds (JVM running for 9.082)", "service.name":"spring-petclinic","process.thread.name":"restartedMain","log.logger":"org.springframework.samples.petclinic.PetClinicApplication"}
{"@timestamp":"2019-08-06T14:08:40.199Z", "log.level":"DEBUG", "message":"init find form", "service.name":"spring-petclinic","process.thread.name":"http-nio-8080-exec-8","log.logger":"org.springframework.samples.petclinic.owner.OwnerController","transaction.id":"28b7fb8d5aba51f1","trace.id":"2869b25b5469590610fea49ac04af7da"}
----

[float]
=== Why ECS logging?

*No parsing of the log file required*::
+
--
ECS-compatible JSON doesn't require the use of Logstash or grok parsing via an ingest node pipeline.
--

*Decently human-readable JSON structure*::
+
--
The first three fields are always `@timestamp`, `log.level` and `message`.
It's also possible to format stack traces so that each element is rendered in a new line.
--

*Enjoy the benefits of a common schema*::
+
--
Use the Kibana {observability-guide}/monitor-logs.html[Logs app] without additional configuration.

Using a common schema across different services and teams makes it possible create reusable dashboards and avoids {ref}/mapping.html#mapping-limit-settings[mapping explosions].
--

*APM Log correlation*::
+
--
If you are using an {apm-agents-ref}/index.html[Elastic APM agent],
you can leverage the {apm-get-started-ref}/observability-integrations.html#apm-logging-integration[log correlation feature] without any additional configuration.
This lets you jump from the {kibana-ref}/spans.html[Span timeline in the APM UI] to the {observability-guide}/monitor-logs.html[Logs app],
showing only the logs which belong to the corresponding request.
Vice versa, you can also jump from a log line in the Logs UI to the Span Timeline of the APM UI.
--

*Broad support for languages and loggers*::
+
--
We have loggers for https://github.com/elastic/ecs-dotnet[.NET],
Go (https://github.com/elastic/ecs-logging-go-zap[zap]),
https://www.elastic.co/guide/en/ecs-logging/java/current/intro.html[Java],
https://github.com/elastic/ecs-logging-js[JavaScript],
https://github.com/elastic/ecs-logging-php[PHP],
https://github.com/elastic/ecs-logging-python[Python],
and https://github.com/elastic/ecs-logging-ruby[Ruby].
--

[float]
==== Additional advantages when using in combination with Filebeat

We recommend shipping the logs with Filebeat.
Depending on the way the application is deployed, you may log to a log file or to stdout (for example in Kubernetes).

Here are a few benefits to over directly sending logs from the application to Elasticsearch:

*Resilient in case of outages*::
+
--
{filebeat-ref}/how-filebeat-works.html#at-least-once-delivery[Guaranteed at-least-once delivery]
without buffering within the application, thus no risk of out of memory errors or lost events.
There's also the option to use either the JSON logs or plain-text logs as a fallback.
--

*Loose coupling*::
+
--
The application does not need to know the details of the logging backend (URI, credentials, etc.).
You can also leverage alternative {filebeat-ref}/configuring-output.html[Filebeat outputs],
like Logstash, Kafka or Redis.
--

*Index Lifecycle management*::
+
--
Leverage Filebeat's default {filebeat-ref}/ilm.html[index lifecycle management settings].
This is much more efficient than using daily indices.
--

*Efficient Elasticsearch mappings*::
+
--
Leverage Filebeat's default ECS-compatible {filebeat-ref}/configuration-template.html[index template].
--
